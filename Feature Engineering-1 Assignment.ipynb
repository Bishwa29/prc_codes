{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca940ad-54fc-446a-8099-20813dab0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature Engineering-1 Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e4190-04d4-4f91-84a5-e1b5f711eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "\n",
    "##A1. Missing values in a dataset are datapoints that do not exist for a unique data entity. For instance: For a dataset consisting of student marks, there could be a situation where marks of english, maths are missing from the dataset.\n",
    "##It is important to handle missing values since missing data could impact any model being created on the data by providing erratic patterns, influencing the output prediction and hence, the overall model usability.\n",
    "\n",
    "##Models such as decision trees, random forests, K-Nearest Neighbors (KNN) are less sensitive to missing values and have built-in mechanisms to handle them effectively. Hence, they also do not require any imputations beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d0d500-3f90-48b3-9c23-cc58d717cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropping rows with missing values:\n",
      "Empty DataFrame\n",
      "Columns: [A, B, C]\n",
      "Index: []\n",
      "\n",
      "DataFrame after dropping columns with missing values:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3]\n",
      "DataFrame after mean imputation:\n",
      "          A    B     C\n",
      "0  1.000000  5.0  11.0\n",
      "1  2.000000  6.0  10.0\n",
      "2  2.333333  7.0  11.0\n",
      "3  4.000000  6.0  12.0\n"
     ]
    }
   ],
   "source": [
    "##Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "\n",
    "##A2. Handling missing data is a crucial step in data preprocessing to ensure accurate model training and predictions. Here are some common techniques used to handle missing data, along with examples using Python:\n",
    "\n",
    "##1. Deleting Rows or Columns with Missing Values\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with missing values\n",
    "data = {'A': [1, 2, np.nan, 4],\n",
    "        'B': [5, np.nan, 7, np.nan],\n",
    "        'C': [np.nan, 10, 11, 12]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "df_dropna_rows = df.dropna()\n",
    "\n",
    "# Drop columns with any missing values\n",
    "df_dropna_cols = df.dropna(axis=1)\n",
    "\n",
    "print(\"DataFrame after dropping rows with missing values:\")\n",
    "print(df_dropna_rows)\n",
    "\n",
    "print(\"\\nDataFrame after dropping columns with missing values:\")\n",
    "print(df_dropna_cols)\n",
    "\n",
    "##Mean/Median/Mode Imputation: Replace missing values with the mean, median, or mode of the non-missing values in the column.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_mean_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(\"DataFrame after mean imputation:\")\n",
    "print(df_mean_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61583b08-4d54-46ac-9178-bdb5d5edcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n",
    "##A3. Imbalanced data refers to a situation in a classification problem where the classes are not represented equally. \n",
    "##Typically, one class (called the minority class) has significantly fewer instances than the other class (called the majority class). \n",
    "##For example, in a binary classification problem, if Class A has 95% of the instances and Class B has only 5%, then the data is imbalanced.\n",
    "\n",
    "##If imbalanced data is not handled properly, several issues can arise:\n",
    "\n",
    "##Biased Models: Machine learning models trained on imbalanced data tend to be biased towards the majority class. They often ignore the minority class because the overall accuracy metric can still be high if the majority class is predicted correctly, even if the minority class is not.\n",
    "\n",
    "##Poor Generalization: Models trained on imbalanced data may not generalize well to new data, especially if the minority class is important but underrepresented. The model may perform poorly on predicting the minority class in unseen data.\n",
    "\n",
    "##Incorrect Assumptions: Some algorithms assume balanced class distribution for optimal performance. Imbalanced data violates this assumption and can lead to suboptimal model performance.\n",
    "\n",
    "##Misleading Evaluation Metrics: Accuracy alone is not a reliable metric for evaluating models on imbalanced data. Models can achieve high accuracy by predicting the majority class, but they may fail to correctly predict instances of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fa100-3338-4063-b6aa-6a4d2ac0f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required.\n",
    "\n",
    "##A4.Up-sampling and down-sampling are techniques used to address class imbalance in machine learning datasets:\n",
    "##Up-sampling: Up-sampling involves increasing the number of instances in the minority class (less represented class) to match the number of instances in the majority class. This is typically done by randomly duplicating examples from the minority class or generating synthetic examples based on existing minority class data.\n",
    "\n",
    "##Example Scenario for Up-sampling: Imagine a credit card fraud detection dataset where only 1% of transactions are fraudulent (minority class), while the rest are legitimate transactions (majority class). In this case, up-sampling would involve increasing the number of fraudulent transactions in the dataset to balance it with the number of legitimate transactions. This helps the model learn more effectively from the minority class examples and improves its ability to detect fraud accurately.\n",
    "\n",
    "##Down-sampling: Down-sampling involves reducing the number of instances in the majority class to match the number of instances in the minority class. This is typically done by randomly removing examples from the majority class until the dataset is balanced.\n",
    "\n",
    "##Example Scenario for Down-sampling: Consider a medical dataset where detecting a rare disease is the minority class (1%) and not having the disease is the majority class (99%). In this case, down-sampling would involve reducing the number of instances of not having the disease to match the number of instances of having the disease. This ensures that the model is not biased towards predicting the majority class and gives equal importance to both classes during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836b03a-f3e3-4eee-a418-283bc637ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n",
    "##A5. Data Augmentation is a technique used primarily in machine learning and computer vision to artificially increase the size and diversity of training datasets by creating modified versions of existing data. \n",
    "##The goal of data augmentation is to improve the generalization and robustness of models, especially when the original dataset is limited in size or diversity.\n",
    "\n",
    "##SMOTE (Synthetic Minority Over-sampling Technique):\n",
    "##SMOTE is a specific technique used for up-sampling the minority class in imbalanced datasets, particularly in classification tasks. \n",
    "##It works by generating synthetic examples rather than duplicating existing ones. SMOTE creates new instances of the minority class by interpolating between existing minority class instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b4e11-5192-4d33-b398-19ce5f581154",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\n",
    "##A6. Outliers in a dataset refers to extreme values that are unnaturally higher or lower than what is present in the dataset.\n",
    "##Outliers can arise due to various reasons such as measurement errors, experimental variability, or genuine but rare events in the data.\n",
    "\n",
    "##It is essential to handle outliers because it impacts the descriptive and inferential statistics to be performed on a dataset.\n",
    "\n",
    "##Impact on Statistical Analysis: Outliers can skew statistical measures and metrics, such as mean and standard deviation, leading to misleading interpretations of data distribution and relationships.\n",
    "\n",
    "##Effect on Machine Learning Models: Outliers can adversely affect the performance and accuracy of machine learning models. Models that are sensitive to outliers, such as linear regression and clustering algorithms, can be heavily influenced by these extreme values, resulting in biased or inefficient predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01fa16-3823-4e6c-bf2b-f76c816fb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "##A7. In order to handle missing data, we can use below techniques such as:\n",
    "\n",
    "##Removal of missing data points: We can delete rows or data instances containing missing data to only keep those with complete data\n",
    "##Imputations using measures of central tendency: We can impute the missing values by using statistics such as mean, median or mode based on nature of the problem\n",
    "##Interpolation: Fill missing values using interpolation methods such as linear interpolation, polynomial interpolation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f444db-4872-4625-9052-974d55f53892",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "\n",
    "##A8. Determining whether missing data is missing at random (MAR) or not at random (MNAR) is crucial for choosing appropriate strategies to handle missing data effectively. \n",
    "##Here are some strategies you can use to investigate the patterns of missing data:\n",
    "\n",
    "##Missing Data Heatmap: Create a heatmap or summary table that shows the presence of missing values across different variables/features. This can help visualize if missingness is concentrated in specific columns or rows.\n",
    "\n",
    "##Summary Statistics: Calculate summary statistics (e.g., mean, median) separately for rows and columns with missing values. Compare these statistics with those of complete cases to identify any patterns.\n",
    "\n",
    "##Domain Knowledge: Utilize domain knowledge to understand plausible reasons for missingness. This can provide insights into whether missing data is related to specific conditions, events, or data collection processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583578a-845f-4dd0-8508-001eb3394c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\n",
    "##A9. In order to address the issue of an imbalanced data (minority output is way smaller than the majority), we can use techniques of up-sampling and down-sampling.\n",
    "##In this particular case, it may make more sense to perform down-sampling so that the rare occurence can be predicted correctly.\n",
    "\n",
    "##Confusion Matrix: Evaluate the model using a confusion matrix to understand true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n",
    "\n",
    "##Precision, Recall, F1-score: Use metrics like precision, recall, and F1-score that are more informative on imbalanced datasets, focusing on the minority class (positive class).\n",
    "\n",
    "##Class Weight Adjustment: Adjust class weights in the machine learning model to penalize misclassifications of the minority class more than the majority class. This helps in improving sensitivity (recall) for the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51552760-08e8-4ee7-8d9b-c0c58ec2f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "\n",
    "##A10. When dealing with an imbalanced dataset in customer satisfaction estimation where the majority of customers are reported to be satisfied, down-sampling the majority class is a common approach to balance the dataset. \n",
    "##Down-sampling involves reducing the number of instances in the majority class to match the number of instances in the minority class (unsatisfied customers in this case).\n",
    "\n",
    "##Below are the steps that can be followed to deal with the problem:\n",
    "\n",
    "##Separate Data by Class: Split the original dataset into two subsets: one for the majority class (satisfied customers) and one for the minority class (unsatisfied customers).\n",
    "##Determine the Size of the Minority Class: Calculate the number of instances in the minority class to know how many samples to keep after down-sampling.\n",
    "##Down-sample the Majority Class: Randomly sample a subset from the majority class to match the size of the minority class. \n",
    "##Combine Down-sampled Majority Class with Minority Class: Concatenate the down-sampled majority class with the original minority class to form a balanced dataset.\n",
    "##Verify the Balanced Dataset: Check the class distribution to ensure the dataset is now balanced between satisfied and unsatisfied customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951e195-fb28-4847-8b96-7f344ea2d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "\n",
    "#A11. ##Below are the steps that can be followed to deal with the problem:\n",
    "\n",
    "##Separate Data by Class: Split the original dataset into two subsets: one for the majority class (common output) and one for the minority class (rare output).\n",
    "##Determine the Size of the Majority Class: Calculate the number of instances in the majority class to know how many samples are needed after up-sampling.\n",
    "##Up-sample the Minority Class: Randomly sample with replacement from the minority class to match the size of the majority class.\n",
    "##Combine Up-sampled Minority Class with Majority Class: Concatenate the up-sampled minority class with the original majority class to form a balanced dataset.\n",
    "##Verify the Balanced Dataset: Check the class distribution to ensure the dataset is now balanced between common and rare outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f596c0-0ab6-4878-a599-56ceebbf2ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78440ec-bfc7-455c-aa64-c55d8fc3d527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3000a5-5c93-41d5-9ab4-8a76b55c68d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57c40d-2d1f-438d-8a8f-da7a6a69cb55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e0497-350a-4fa5-9cd9-6d5afc003c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
